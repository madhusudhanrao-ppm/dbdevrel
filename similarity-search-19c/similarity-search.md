# How Can I Create Semantic Similarity Search in Oracle Database 19c?
 
## Introduction

In this lab, you will learn how to **create a similarity search application using LangChain, Streamlit, and Sentence Transformers Hugging Face Model with Oracle Autonomous AI Database 19c**.

**Similarity search** is a technique that finds items in a dataset that are most similar to a query, rather than looking for exact matches. It works by representing items as numerical vectors (called embeddings) and then using mathematical formulas like cosine similarity or Euclidean distance to find the vectors closest to the query vector. This allows systems to find related items based on shared features, making it useful for applications like image and text search, recommendation systems, and AI-driven analysis.

**Semantic search** is a technique that understands the contextual meaning and intent behind a user's query, going beyond simple keyword matching to find relevant results. It works by converting text into numerical representations called vectors, which are stored in a vector database. The system then compares the vector of a new query to existing vectors to find the most similar ones, effectively connecting ideas even when the exact words are different.

How it works

* **Vectorization**: Data, such as text, images, or audio, is converted into numerical vectors (embeddings). These vectors capture the essence or features of the original item.
* **Similarity calculation**: A similarity measure is used to calculate the "distance" or "angle" between the query vector and the vectors of the items in the dataset.
* **Ranking**: Items are ranked based on their similarity to the query, with the most similar items appearing first.
Retrieval: The system retrieves the items with the highest similarity scores

[SentenceTransformers](https://huggingface.co/sentence-transformers) is a Python framework for state-of-the-art sentence, text and image embeddings.

[all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.



Estimated Time: 2 to 5 minutes.  
 
### Objectives

In this short sprint, you will:
 
* Create a similarity search application using LangChain, Streamlit and Sentence Transformers Hugging Face Mode.

    <!-- [Demo video on Create Oracle Autonomous AI Database](youtube:V2PETW_F7XI:large)  -->

### Prerequisites

This lab assumes you have:

* Oracle cloud account and privileges to create & manage Oracle Autonomous AI Database
* Oracle Autonomous Database 19c has been created and is running.
* Basic knowledge of Python programming language.
* Basic knowledge of SQL and Oracle Database concepts.

 
**Download Source Code** - similaritysearch.py and Create Table script - create-table.sql from [GitHub Repository](https://github.com/madhusudhanrao-ppm/dbdevrel/tree/main/source-codes/similaritysearch) 


## Task 1: Create Table and Insert Sample Records

1. Create Table in Oracle Database 19c (Alternatively You can also use 23ai or 26ai) and insert few sample records

    ```
    <copy>
    CREATE TABLE "MYNOTES" 
    (	
        "ID" NUMBER GENERATED BY DEFAULT ON NULL AS IDENTITY MINVALUE 1 MAXVALUE 99999999 
         INCREMENT BY 1 START WITH 4 CACHE 20 NOORDER  NOCYCLE  NOKEEP  NOSCALE  NOT NULL ENABLE, 
        "NOTES" VARCHAR2(4000 CHAR),  
        CONSTRAINT "MYNOTES_ID_PK" PRIMARY KEY ("ID")
        USING INDEX  ENABLE
    ) ;

    -- Insert records
    INSERT INTO MYNOTES (notes) VALUES ('Travel to Kashmir was an unforgettable experience with stunning landscapes.');
    INSERT INTO MYNOTES (notes) VALUES ('Hotel Booking in Delhi was confirmed for the weekend.'); 
    INSERT INTO MYNOTES (notes) VALUES ('Arrived in Paris, the Eiffel Tower was breathtaking at sunset.');
    INSERT INTO MYNOTES (notes) VALUES ('Loved the croissants at a tiny bakery near the Seine.');
    INSERT INTO MYNOTES (notes) VALUES ('Tokyo streets are incredibly clean and efficient.');
    INSERT INTO MYNOTES (notes) VALUES ('Central Park was a perfect escape from the city buzz.');
    INSERT INTO MYNOTES (notes) VALUES ('Bangkok night markets are a mustâ€‘try for street food.');
    INSERT INTO MYNOTES (notes) VALUES ('Sydney Opera House illuminated at night is unforgettable.');
    INSERT INTO MYNOTES (notes) VALUES ('Romeâ€™s ancient ruins are best explored with a guide.');
    INSERT INTO MYNOTES (notes) VALUES ('Tapas in Barcelona were small but packed with flavor.');
    INSERT INTO MYNOTES (notes) VALUES ('Dubaiâ€™s desert safari was an exhilarating experience.');
    INSERT INTO MYNOTES (notes) VALUES ('Cape Townâ€™s Table Mountain offered stunning panoramic views.'); 
    INSERT INTO MYNOTES (notes) VALUES ('Patient tolerated surgery well; margins clear.'); 
    INSERT INTO MYNOTES (notes) VALUES ('Started on pembrolizumab - mild fatigue reported.'); 
    INSERT INTO MYNOTES (notes) VALUES ('Completed 6 cycles of FOLFOX; CEA levels decreasing.'); 
    INSERT INTO MYNOTES (notes) VALUES ('Androgen deprivation therapy initiated; PSA dropped to 0.8 ng/mL.'); 
    INSERT INTO MYNOTES (notes) VALUES ('Bilateral lung metastases stable after 8 cycles of nivolumab.'); 
    INSERT INTO MYNOTES (notes) VALUES ('CR achieved after induction; proceeding to consolidation.'); 
    INSERT INTO MYNOTES (notes) VALUES ('Started on gemcitabine + nabâ€‘paclitaxel; mild neutropenia noted.'); 
    INSERT INTO MYNOTES (notes) VALUES ('Debulking surgery successful; plan for platinumâ€‘based chemo.'); 
    INSERT INTO MYNOTES (notes) VALUES ('PET scan shows complete metabolic response after 4 cycles of ABVD.'); 
    INSERT INTO MYNOTES (notes) VALUES ('Total thyroidectomy performed; awaiting radioactive iodine.');
    INSERT INTO MYNOTES (notes) VALUES ('Breast cancer screening scheduled for next month.');
    INSERT INTO MYNOTES (notes) VALUES ('Lung cancer screening scheduled for next month.');
    </copy>
      ``` 

## Task 2: Download Wallet and Connection Details

1. From the top right navigation menu click on **Database Connection** button

    ![DB Conn](images/db-conn.png  )

2. Download wallet and Copy connection details. 

    ![Wallet](images/copy-connection.png  ) 

    Provide wallet password and save the wallet.

3. Copy and save TNS Name, which would be of the following format, where database name and region will change. we will need this details for database connection. 

    ```
    devdbhs556l_high = (description= (retry_count=20)(retry_delay=3)(address=(protocol=tcps)(port=1522)(host=adb.us-phoenix-1.oraclecloud.com))(connect_data=(service_name=wkrfstesta1jcu_devdbhs556l_high.adb.oraclecloud.com))(security=(ssl_server_dn_match=yes)))
    ```
  
## Task 3: Setup Python Environment

1. Create Python environment and install the required libraries. 

    ```
    python3 -m venv myproject_env   
    source myproject_env/bin/activate    
    pip install streamlit langchain langchain-community sentence-transformers faiss-cpu oracledb
    streamlit run similaritysearch.py  
    ```

## Task 4: Create Streamlit Application for Similarity Search

1. Lets write similaritysearch.py and Imports

    ```
    import os
    import streamlit as st
    from langchain.embeddings.huggingface import HuggingFaceEmbeddings
    from langchain.vectorstores import FAISS
    from langchain.schema import Document
    import oracledb 
    ```

2. Page setup and Create Database Connection

    ``` 
    # Page config
    st.set_page_config(page_title="Semantic Similarity Search", layout="wide")
    st.title("ðŸ” Semantic Similarity Search with LangChain & Streamlit")

    # Initialize session state
    if "embeddings_model" not in st.session_state:
        st.session_state.embeddings_model = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
    if "vector_store" not in st.session_state:
        st.session_state.vector_store = None
    if "documents" not in st.session_state:
        st.session_state.documents = []

    # Helper: Fetch sentences from Oracle DB
    @st.cache_resource
    def fetch_from_oracle(
        table_name: str = None,
        column_name: str = None,
        max_rows: int = 1000
    ) -> list:
        user = "<DB-Username>"
        pwd = "<DB-Password>"
        tns_name = "indadw_high"   
        wall_config_dir = "/Wallet_folder/"
        wall_pwd = "<Wallet_Password>" 
        table = "<MYNOTES>"
        col = "NOTES"

        if not (user and pwd and tns_name):
            st.warning("Oracle credentials not set. Using sample data.")
            return None

        conn = None
        try:
            conn = oracledb.connect(user=user, 
                                password=pwd,
                                dsn=tns_name,
                                config_dir=wall_config_dir,
                                wallet_location=wall_config_dir,
                                wallet_password=wall_pwd)
            cur = conn.cursor()
            sql = f"SELECT {col} FROM {table} WHERE {col} IS NOT NULL AND ROWNUM <= :maxrows"
            cur.execute(sql, [max_rows])
            rows = cur.fetchall()
            return [r[0] for r in rows if r and r[0] is not None]
        except Exception as e:
            st.error(f"DB Error: {e}")
            return None
        finally:
            if conn:
                conn.close()

    # Sidebar: Load data source
    st.sidebar.header("âš™ï¸ Configuration")
    data_source = st.sidebar.radio("Select Data Source", ["Sample Data", "Oracle Database"])

    documents_list = []
    if data_source == "Oracle Database":
        st.sidebar.info("Loading from Oracle DB...")
        sentences = fetch_from_oracle()
        if sentences:
            documents_list = [Document(page_content=s, metadata={"source": "oracle"}) for s in sentences]
            st.sidebar.success(f"Loaded {len(documents_list)} documents from Oracle")
    else:
        # Sample data fallback
        sample_sentences = [
            "I want to open a account.",
            "I want a credit card.",
            "I need to update my address.",
            "I want to apply for a loan.",
            "How do I check my balance?",
            "I lost my debit card."
        ]
        documents_list = [
            Document(page_content=s, metadata={"source": "sample"}) 
            for s in sample_sentences
        ]
        st.sidebar.success(f"Loaded {len(documents_list)} sample documents")  
    ```

3. Build vector store

    ```
    # Build vector store
    if st.sidebar.button("ðŸ”„ Build Vector Store"):
        with st.spinner("Building vector store..."):
            st.session_state.vector_store = FAISS.from_documents(
                documents_list,
                st.session_state.embeddings_model
            )
            st.session_state.documents = documents_list
            st.sidebar.success("âœ… Vector store built!") 
    ```

4. Main search interface

    ``` 
    st.header("Search Documents")

    if st.session_state.vector_store is None:
        st.info("ðŸ‘ˆ Click 'Build Vector Store' in the sidebar to get started")
    else:
        col1, col2 = st.columns([3, 1])
        
        with col1:
            query = st.text_input(
                "Enter your search query:",
                placeholder="e.g., open an account"
            )
        
        with col2:
            k_results = st.number_input("Top K results", min_value=1, max_value=10, value=3)

        if query:
            with st.spinner("Searching..."):
                docs = st.session_state.vector_store.similarity_search(query, k=k_results)
                # Compute similarity scores manually
                query_embedding = st.session_state.embeddings_model.embed_query(query)
                results = []
                for doc in docs:
                    doc_embedding = st.session_state.embeddings_model.embed_query(doc.page_content)
                    score = 1 - (sum(a*b for a, b in zip(query_embedding, doc_embedding)) / 
                                (sum(a**2 for a in query_embedding)**0.5 * sum(b**2 for b in doc_embedding)**0.5))
                    results.append((doc, score))

            st.subheader(f"Top {len(results)} Results")
            
            for i, (doc, score) in enumerate(results, 1):
                with st.container():
                    col_rank, col_content, col_score = st.columns([0.5, 3, 1])
                    
                    with col_rank:
                        st.metric("Rank", i)
                    
                    with col_content:
                        st.write(f"**{doc.page_content}**")
                        if doc.metadata:
                            st.caption(f"Source: {doc.metadata.get('source', 'unknown')}")
                    
                    with col_score:
                        st.metric("Similarity", f"{(1 - score):.3f}")
                
                st.divider()
    ```

5. Sidebar: Show loaded documents and Footer
 
    ``` 
    with st.sidebar.expander("ðŸ“„ View Loaded Documents"):
        if st.session_state.documents:
            for i, doc in enumerate(st.session_state.documents, 1):
                st.write(f"{i}. {doc.page_content[:80]}...")
        else:
            st.write("No documents loaded yet")

    # Footer
    st.sidebar.divider()
    st.sidebar.markdown("**Setup Instructions:**")
    st.sidebar.markdown("Select Datasource as 'Oracle Database'")
    st.sidebar.markdown("Click on 'Build Vector Store' to load data from Oracle DB.")
    ```

## Task 5: Run the Python Application

1. Run the streamlit code, access the application at [localhost:8501](http://localhost:8501/)

    ```
    similaritysearch % streamlit run similaritysearch.py
    ```

2.  Select Datasource as 'Oracle Database', Click on 'Build Vector Store' to load data from Oracle Database 19c.

    ![Navigation](images/01.png )
    
3. Search for **Travel Notes**

    ![Create Stack](images/02.png )

3. Search for **Clean City**

    ![Create Stack](images/03.png )

3. Search for **Cancer Treatment**

    ![Create Stack](images/04.png )

3. Search for **Surgical Plan**

    ![Create Stack](images/05.png )
   
## Learn More & Downloads
 
* [Autonomous AI Database for Developers](https://docs.oracle.com/en-us/iaas/autonomous-database-serverless/doc/autonomous-database-for-developers.html) 
* [Download Source code](https://github.com/madhusudhanrao-ppm/dbdevrel/tree/main/source-codes)
* [Direct ORM deployment link](https://cloud.oracle.com/resourcemanager/stacks/create?zipUrl=https://objectstorage.us-phoenix-1.oraclecloud.com/p/jtfUsV33KtLR937hWybAgrq8qtuQQuAaIw1K_VBThhlUF6Z1HYF0Ai50sQlp06bQ/n/oradbclouducm/b/medical_transcripts/o/Terraform/oracle-lakehouse-devedition-stack.zip)
* [See Autonomous AI Database for Developers Billing and Tenancy Service Limit for details] (https://docs.oracle.com/en-us/iaas/autonomous-database-serverless/doc/autonomous-database-for-developers-billing.html)

## Acknowledgements

* **Author** - Madhusudhan Rao, Principal Product Manager, Oracle Database DevRel 
* **Last Updated By/Date** - 3rd Dec, 2025
